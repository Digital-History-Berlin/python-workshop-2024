{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üíª Einf√ºhrung in Topic Modeling mit Python - Step 2: Train the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "\n",
    "import pandas as pd # load source data\n",
    "\n",
    "import gensim.corpora as corpora \n",
    "from gensim.models import LdaModel, CoherenceModel # evaluation\n",
    "from gensim.test.utils import datapath # to save model data\n",
    "\n",
    "from pprint import pprint # \"pretty print\" additional output method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einlesen und vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "source = pd.read_csv(\"../daten/speeches-bundesregierung_preprocessed.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract speeches\n",
    "speeches = source.loc[:, \"preprocessed_text\"].tolist()\n",
    "\n",
    "# convert strings to word lists\n",
    "speeches_list = []\n",
    "for speech in speeches:\n",
    "    speeches_list.append(speech.split())\n",
    "\n",
    "print(speeches_list[-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textdaten quantifizierbar machen\n",
    "\n",
    "1. Wort-ID-Dictionary erzeugen\n",
    "2. Auf Basis des Wort-ID-Dictionaries wird jedes Dokument umgewandelt in eine Bag-of-Words der Form: ID(=Wort): H√§ufigkeit im Dokument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary where an unique id is assigned to each word in the corpus \n",
    "# this dicitionary is used as a reference in the modeling-process\n",
    "id2word = corpora.Dictionary(speeches_list)\n",
    "\n",
    "# save for future reference, update path\n",
    "#from datetime import datetime\n",
    "#id2word.save(f\"{datetime.now()}-FILENAME.dict\")\n",
    "\n",
    "# load\n",
    "#id2word.load(r\"PATH.dict\")\n",
    "\n",
    "# view id2word-content\n",
    "#print(id2word.token2id)\n",
    "\n",
    "# create text corpus \n",
    "text_corpus = speeches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term document frequency (bag of words) -> converts tokenized documents to sparse vector\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for text in text_corpus:\n",
    "    corpus.append(id2word.doc2bow(text))\n",
    "\n",
    "#corpus = [id2word.doc2bow(text) for text in text_corpus] # above for-loop as list comprehension\n",
    "\n",
    "# save doc2bow for future use, update path\n",
    "#corpora.MmCorpus.serialize(f\"{datetime.now()}-FILENAME\", corpus)  \n",
    "\n",
    "# View\n",
    "print(f\"Die Bag of Words f√ºr obiges Dokument sieht f√ºr die Topic-Modellierung so aus:\\n {corpus[-3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplarisches Topic-Modell berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train topic model, may take some time in Binder \n",
    "# takes up to 30 minutes (with 2000 iterations), depending on memory usage and internet speed\n",
    "\n",
    "ldamodel = LdaModel(corpus=corpus,     # bag of words\n",
    "                    num_topics=10,     # number of topics to be extracted from corpus, default=100\n",
    "                    id2word=id2word,   # dictionary\n",
    "                    alpha=\"auto\",      # insert: \"symmetric\" (default), \"asymmetric\" or \"auto\"\n",
    "                    iterations=50,     # default: 50\n",
    "                    random_state=100,  # useful for reproducibility\n",
    "                    chunksize=500,     # number of documents to be used in each training chunk, default=2000 \n",
    "                    passes=10)         # how many times should the algorithm pass over the whole corpus, default=1, n > 1 slows down modeling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model (four files) to temporary files - can be copied and pasted \n",
    "\n",
    "#temp_file = datapath(\"topic-model\")\n",
    "#ldamodel.save(temp_file)\n",
    "\n",
    "# load model\n",
    "#ldamodel = LdaModel.load(\"UPDATE PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspektion des Topic-Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all topics with 30 most dominant words\n",
    "topics = ldamodel.print_topics(num_topics=-1, num_words=30)\n",
    "pprint(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# extract topics for inspection\n",
    "topics = ldamodel.print_topics(num_topics=-1, num_words=30)\n",
    "\n",
    "with open(\"../daten/topic-model/topics.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    csv_writer = csv.writer(file, delimiter=\"+\")\n",
    "    for i, e in topics:\n",
    "        i = \"Topic \" + str(i)\n",
    "        csv_writer.writerow([i, e])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation des Topic-Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute coherence score\n",
    "# computation takes some time (especially in Binder)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=ldamodel, texts=text_corpus, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f\"Coherence Score: {coherence_lda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraktion der Dokument-Topic-Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topics = []\n",
    "\n",
    "for doc in corpus:\n",
    "    # extract all topics with corresponding distribution, specify minimum_probability on order to fetch all distribution values\n",
    "    doc_topics.append(ldamodel.get_document_topics(doc, minimum_probability=0.0)) \n",
    "    \n",
    "print(doc_topics[0]) # distribution values represented as complex numbers - will be transformed in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "\n",
    "# create a dictionary-like object which is given a list as initial value to easily add data\n",
    "dt_dict = defaultdict(list) \n",
    "\n",
    "for doc in doc_topics:\n",
    "    for tuples in doc: \n",
    "        dt_dict[f\"Topic {tuples[0]}\"].append(tuples[1])\n",
    "        \n",
    "dt_dict[\"Topic 0\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas dataframe from dictionary, keys=column names, each row represents one document\n",
    "\n",
    "dt_matrix = pd.DataFrame.from_dict(dt_dict) \n",
    "dt_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add metadata\n",
    "dt_matrix[\"date\"] = source.date\n",
    "dt_matrix[\"year\"] = source.year\n",
    "\n",
    "dt_matrix.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe for future use\n",
    "dt_matrix.to_csv(\"../daten/topic-model/document-topic-matrix.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung eines Topics im Verlauf des zeitlich geordneten Korpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "dt_matrix = pd.read_csv(\"../daten/topic-model/document-topic-matrix.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index \n",
    "dt_matrix = dt_matrix.set_index(\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize topic; important: the data is not normalized \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,7), dpi=360)\n",
    "\n",
    "dt_matrix[\"Topic 5\"].plot(label=\"Rohdaten\", color=\"#2F4F4F\", linewidth=3, marker=\"o\")\n",
    "#dt_matrix.groupby(\"year\")[\"Topic 5\"].median().plot(label=\"Median\", color=\"blue\", linewidth=3, marker=\"o\") \n",
    "#dt_matrix.groupby(\"year\")[\"Topic 5\"].mean().plot(label=\"Mean\", color=\"magenta\", linewidth=3, marker=\"o\") \n",
    "\n",
    "plt.title(\"Topic-Verteilung auf Basis der Rohdaten pro Jahr\", fontsize=22, fontstyle=\"oblique\")\n",
    "plt.xlabel(\"Jahr\", fontsize=18, fontstyle=\"italic\")\n",
    "plt.ylabel(\"Distribution\", fontsize=18, fontstyle=\"italic\")\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung des Topic-Modells mit pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize topic model\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "vis = pyLDAvis.gensim_models.prepare(ldamodel, corpus, id2word)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(vis, \"../daten/topic-model/topic-model.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Abschlussaufgabe: \n",
    "Probieren Sie gerne einmal verschiedene Parameter-Einstellungen f√ºr die *Topic-Anzahl*, *chunksize* oder *alpha* oben im Codeblock aus, indem Sie einfach die Parameterwerte ver√§ndern.\n",
    "Vergleichen Sie, wie sich das Ergebnis ver√§ndert. Setzen Sie ggf. \"passes\" auf den Default-Wert von 1, um die Berechnungsgeschwindkigkeit in Binder zu optimieren.\n",
    "\n",
    "#### Zus√§tzliche Parameter k√∂nnen sein:\n",
    "- eval_every=10 # evaluate model based on perplexity every n iterations - slows down modeling process \n",
    "- update_every=1 # update the model every given n for chunksize chunks, default=1 \n",
    "\n",
    "\n",
    "**Abschlie√üender Hinweis:** Topic-Modeling ist ein statistisches Verfahren, das hei√üt, je mehr Daten, desto belastbarer sind die Modellierungsergebnisse. Dieses Korpus aus Reden ist nicht ideal. Es ist relativ klein und die Daten noch nicht optimal aufbereitet. Haben Sie vielleicht ein eigenes Datenkorpus? Dann probieren Sie gerne diesen Workflow anhand Ihrer Daten aus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab2bc7d93ca595a8547f73d141c9dac102da280dfea0255e9d7a3267ba9f4e63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
