{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📝 Übung zum Data Mining mit Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2: Anzahl der Token pro Rede ermitteln und speichern\n",
    "\n",
    "Wir wollen die Anzahl der Token, also die Länge der einzelnen Reden ermitteln und die Informationen wieder im Dataframe als neue Spalte speichern.\n",
    "\n",
    "- Lesen Sie dazu die Texte aus der Spalte `text` aus und speichern Sie sie in einer Liste. \n",
    "- Sorgen Sie nun dafür, dass die einzelnen Texte in Wortlisten zerlegt werden und bestimmen Sie die Länge der einzelnen Wortlisten. \n",
    "- Die Länge der Texte soll als neue Spalte `ntokens` zum Dataframe hinzugefügt werden.\n",
    "\n",
    "⏳ 10 Minuten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle bitte ausführen: Pandas importieren und Dataframe einlesen\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../daten/speeches-bundesregierung.csv\", parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df.loc[:, \"text\"].to_list()         # Texte in Liste einlesen\n",
    "\n",
    "ntokens = []                                \n",
    "for text in texts:                          # Die einzelnen Texten per Schleife durchgehen\n",
    "    ntokens.append(len(text.split()))       # jeden Text mit der Funktion split() in eine Liste zerlegen und die Länge der Liste ermitteln und zur Liste ntokens hinzufügen\n",
    "\n",
    "df.loc[:, \"ntokens\"] = ntokens              # fertige Liste zum Dataframe hinzufügen\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3: Datenabfragen gestalten\n",
    "\n",
    "Erkunden Sie das Korpus von Reden von Angehörigen der Bundesregierung, um ein tieferes Verständnis verschiedener thematischer Schwerpunkte und die Nutzung spezifischer Begrifflichkeiten über die Zeit zu gewinnen. \n",
    "\n",
    "1. Extrahieren Sie alle Reden, die im Jahr 2001 gehalten wurden.\n",
    "2. Ermitteln Sie die Anzahl der Reden, die das Wort \"Europa\" enthalten.\n",
    "3. Identifizieren Sie Reden, die den Begriff \"digital\" und \"Digitalisierung\" enthalten. \n",
    "4. Suchen Sie nach Reden, die zwischen 2000 und 2010 gehalten wurden, die sich auf Umweltthemen beziehen. In Frage kommen hierfür Begriffe wie \"Umwelt\", \"Klima\", \"Nachhaltigkeit\" oder ähnliches. Formulieren Sie eine Abfrage, die mehrere dieser Begriffe berücksichtigt. Achten Sie ggf. darauf, wie die Bedingungen mit runden Klammern gruppiert werden müssen.\n",
    "\n",
    "Hinweise:\n",
    "- Für diese Aufgabe benötigen Sie die logischen Operatoren für *UND* (`&`) und *ODER* (`|`) - letzteres ist je nach Tastatur auf einer anderen Taste. Wichtig: In Python hat der logische Operator `&` eine höhere Priorität als `|`. Bei Abfragen, die beide Operatoren verwenden, muss also darauf geachtet werden, wie die Abfragebestandteile mit runden Klammern gruppiert werden.\n",
    "- Die Funktion `contains()` arbeitet standardmäßig case-sensitiv. Wenn Sie eine case-insensitive Suche durchführen möchten, können Sie den Parameter `case=False` ergänzen.\n",
    "\n",
    "⏳ 20 Minuten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle bitte ausführen: Pandas importieren und Dataframe einlesen\n",
    "import pandas as pd\n",
    "df = pd.read_json(\"../daten/output/speeches-bundesregierung_bearbeitet.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erste Aufgabe\n",
    "mask = df.loc[:, \"date\"].dt.year == 2001\n",
    "year_2001 = df.loc[mask, [\"date\", \"text\"]]\n",
    "year_2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zweite Aufgabe\n",
    "mask = df.loc[:, \"text\"].str.contains(\"Europa\").sum()\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dritte Aufgabe\n",
    "mask = (df.loc[:, \"text\"].str.contains(\"digital\", case=False)) \\\n",
    "        & (df.loc[:, \"text\"].str.contains(\"Digitalisierung\", case=False))\n",
    "\n",
    "df_digital = df.loc[mask, :]\n",
    "print(df_digital.shape)\n",
    "df_digital.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(df_digital.loc[:, [\"date\", \"person\", \"text\"]].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vierte Aufgabe; Oder-Abfragen sind durch runde Klammern als eine Gruppe zusammengefasst\n",
    "\n",
    "mask = ((df.loc[:, \"text\"].str.contains(\"Umwelt\", case=False)) \\                \n",
    "        | (df.loc[:, \"text\"].str.contains(\"Klima\", case=False)) \\\n",
    "        | (df.loc[:, \"text\"].str.contains(\"Nachhaltigkeit\", case=False))) \\\n",
    "        & (df.loc[:, \"date\"].dt.year >= 2000) \\\n",
    "        & (df.loc[:, \"date\"].dt.year <= 2010) \n",
    "\n",
    "df_umwelt = df.loc[mask, :]\n",
    "print(df_umwelt.shape)\n",
    "df_umwelt.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mininghistoriansweb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
