{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù √úbung: Dateien verarbeiten\n",
    "\n",
    "## Aufgabe 1: Verarbeitung einer Textdatei\n",
    "\n",
    "- √ñffnen Sie die Textdatei `kafka_verwandlung_1915.txt`, die sich im Ordner `daten` befindet. \n",
    "\n",
    "- Lesen Sie den Text aus der Datei ein und speichern Sie ihn in der Variablen `metamorphosis`.\n",
    "\n",
    "- Wenden Sie eine Vorverarbeitungsfunktion auf den eingelesenen Text an. Diese Funktion k√∂nnen Sie aus dem Notebook U3 wiederverwenden. Passen Sie die Funktion jedoch so an, dass sie den bereinigten Text als einen zusammenh√§ngenden String zur√ºckgibt, anstatt als Liste von W√∂rtern. \n",
    "\n",
    "- Speichern Sie den vorverarbeiteten Text in einer neuen Textdatei. W√§hlen Sie einen geeigneten Dateinamen (z.B. `kafka_verwandlung_1915_preprocessed.txt`), der deutlich macht, dass es sich um die bearbeitete Version des Originaltextes handelt, und speichern Sie die Datei im Ordner `daten/output`. \n",
    "\n",
    "‚è≥ 15 Minuten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textdatei √∂ffnen\n",
    "with open(\"../daten/kafka_verwandlung_1915.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    # Text einlesen und in Variablen speichern\n",
    "    metamorphosis = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text vorverarbeiten, dazu kann die Funktion aus U3 wiederverwendet werden\n",
    "def preprocess_text(text):\n",
    "\n",
    "    \"\"\"The function returns a list object containing preprocessed words.\n",
    "    Preprocessing steps include: removal of punctuation and stopwords, lowercasing\n",
    "    and tokenization based on whitespaces.\n",
    "    \n",
    "    Args: string\n",
    "    Returns: list of preprocessed tokens\n",
    "    \"\"\"\n",
    "\n",
    "    # Entfernen der Satzzeichen\n",
    "    punct = \".,;:!?\\\"'\"   # beliebig erweiterbar, alternativ: Liste\n",
    "    for char in punct:\n",
    "        text = text.replace(char, \"\")\n",
    "\n",
    "    # Lower-casing\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenisierung anhand von Whitespaces\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Entfernen von Stoppw√∂rtern\n",
    "    stopwords = [\"ein\", \"der\", \"das\", \"die\", \"und\", \"sowie\", \"ist\"] # beliebig erweiterbar, Bibliotheken wie NLTK bieten umfangreiche Stoppwortlisten\n",
    "\n",
    "    token_list = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if token not in stopwords:\n",
    "            token_list.append(token)\n",
    "\n",
    "    preprocessed_text = \" \".join(token_list)\n",
    "\n",
    "    # Ausgabe des bereinigten Textes\n",
    "    return preprocessed_text\n",
    "\n",
    "\n",
    "# Anwendung der Funktion auf den eingelesenen Text\n",
    "preprocessed_text = preprocess_text(metamorphosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern des vorverarbeiteten Texts in eine neue TXT-Datei\n",
    "with open(\"../daten/output/kafka_verwandlung_1915_preprocessed.txt\", \"w\", encoding=\"utf-8\") as write_file:\n",
    "    write_file.write(preprocessed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2: Worth√§ufigkeiten in JSON persistent abspeichern\n",
    "\n",
    "- Lesen Sie den in der vorherigen Aufgabe vorverarbeiteten Text aus der Datei `kafka_verwandlung_1915_preprocessed.txt` als String ein und speichern ihn in der Variablen `metamorphosis`.\n",
    "\n",
    "- Verwenden Sie die Funktion aus Aufgabe 3 in Notebook U3, um die Worth√§ufigkeiten in dem eingelesenen Text zu ermitteln. Diese Funktion nimmt einen Text als Eingabe und gibt ein Dictionary zur√ºck, das die W√∂rter des Textes als Schl√ºssel und ihre jeweiligen H√§ufigkeiten als Werte enth√§lt.\n",
    "\n",
    "- Speichern Sie das Dictionary im Ordner `daten/output/` in eine Datei mit dem Dateinamen `kafka_verwandlung_1915_frequencies.json`. Importieren Sie dazu das Modul `json` und verwenden Sie speziell die Funktion `json.dump()`, um die Daten direkt in die JSON-Datei zu schreiben; denken Sie dabei auch an die Indentierung.\n",
    "\n",
    "‚è≥ 15 Minuten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../daten/output/kafka_verwandlung_1915_preprocessed.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    # Text einlesen und in Variablen speichern\n",
    "    metamorphosis = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Aufgabe 3 in Notebook U3\n",
    "def count_absolute_frequency(text):\n",
    "    \"\"\"The function returns a dictionary object containing the absolute frequency for\n",
    "    each unique token in a given text.\n",
    "    \n",
    "    Args: string\n",
    "    Returns: dictionary with frequencies\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_text = text.split()\n",
    "\n",
    "    # initialize empty dictionary\n",
    "    frequencies = {}\n",
    "\n",
    "    # compute absolute frequency\n",
    "    for token in tokenized_text:\n",
    "        if token in frequencies:\n",
    "            frequencies[token] = frequencies[token] + 1\n",
    "        else:\n",
    "            frequencies[token] = 1  \n",
    "\n",
    "    return frequencies\n",
    "\n",
    "# Anwendung der Funktion auf den eingelesenen Text\n",
    "metamorphosis_freq = count_absolute_frequency(metamorphosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metamorphosis_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Speichern von Dictionaries als JSON-Datei mit Layout-Informationen > verbessert die Lesbarkeit\n",
    "with open(\"../daten/output/kafka_verwandlung_1915_frequencies.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(metamorphosis_freq, json_file, indent = 4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3: Tabellarische Daten erstellen und in einer CSV speichern\n",
    "\n",
    "- Definieren Sie eine Liste von B√ºchern, wobei jedes Buch durch ein Dictionary repr√§sentiert wird. Jedes Dictionary soll folgende Schl√ºssel haben: Titel, Autor:in und Erscheinungsjahr.\n",
    "\n",
    "- Verwenden Sie das `csv`-Modul, um eine CSV-Datei mit den Buchinformationen zu erstellen. Die erste Zeile der CSV-Datei soll die Spalten√ºberschriften enthalten.\n",
    "\n",
    "- Speichern Sie die CSV-Datei unter einem geeigneten Dateinamen in dem Ordner `output`.\n",
    "\n",
    "‚è≥ 15 Minuten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Liste von B√ºchern\n",
    "buecher = [\n",
    "    {\"Titel\": \"Frankenstein\", \"Autor:in\": \"Mary Shelley\", \"Erscheinungsjahr\": \"1818\"},\n",
    "    {\"Titel\": \"Zum Leuchtturm\", \"Autor:in\": \"Virginia Woolf\", \"Erscheinungsjahr\": \"1927\"},\n",
    "    {\"Titel\": \"Stolz und Vorurteil\", \"Autor:in\": \"Jane Austen\", \"Erscheinungsjahr\": \"1813\"},\n",
    "    {\"Titel\": \"Der gro√üe Gatsby\", \"Autor:in\": \"F. Scott Fitzgerald\", \"Erscheinungsjahr\": \"1925\"},\n",
    "    {\"Titel\": \"Beloved\", \"Autor:in\": \"Toni Morrison\", \"Erscheinungsjahr\": \"1987\"}\n",
    "]\n",
    "\n",
    "# CSV-Datei erstellen\n",
    "with open(\"../daten/output/buecher.csv\", mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"Titel\", \"Autor:in\", \"Erscheinungsjahr\"])\n",
    "    writer.writeheader()  # Spalten√ºberschriften schreiben\n",
    "    for buch in buecher:\n",
    "        writer.writerow(buch)\n",
    "\n",
    "print(f\"Die CSV-Datei wurde erfolgreich erstellt.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mininghistoriansweb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
